---
layout: publication
title: "Generating Adversarial Examples for Holding Robustness of Source Code Processing Models"
authors: Huangzhao Zhang, Zhuo Li, Ge Li, Lei Ma, Yang Liu, Zhi Jin
conference: AAAI
year: 2020
additional_links:
   - {name: "Proceedings", url: "https://ojs.aaai.org/index.php/AAAI/article/view/5469"}
tags: ["adversarial"]
---
Automated  processing,  analysis,  and  generation  of  source code are among the key activities
in software and system life-cycle. To this end, while deep learning (DL) exhibits a certain level
of capability in handling these tasks, the current state-of-the-art DL models still suffer from
non-robust issues and can be easily fooled by adversarial attacks.

Different  from  adversarial 
attacks  for  image,  audio,  andnatural  languages,  the  structured  nature  of  programming
languages  brings  new  challenges.  In  this  paper,  we  propose a Metropolis-Hastings
sampling-based identifier renaming technique, named Metropolis-Hastings Modifier (MHM),
which  generates  adversarial  examples  for  DL  models  specialized for source code processing.
Our in-depth evaluation on a functionality classification benchmark demonstrates the
effectiveness  of  MHM  in  generating  adversarial  examples of source code. The higher robustness
and performance enhanced through our  adversarial training with MHM further confirms the usefulness
of DL models-based method for future fully automated source code processing.

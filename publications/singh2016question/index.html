<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107339008-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments)};
    gtag('js', new Date());
    gtag('config', 'UA-107339008-1');
  </script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="keywords" content="machine learning, source code, big code, naturalness, software engineering, programming languages">

  <title>
    
      Question Independent Grading using Machine Learning: The Case of Computer Program Grading &middot; Machine Learning for Big Code and Naturalness
    
  </title>

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link rel="search" href="/public/opensearchdescription.xml" 
      type="application/opensearchdescription+xml" 
      title="ML4Code" />

  <script src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  
  <link rel="stylesheet" type="text/css" href="//cdn.datatables.net/1.10.16/css/jquery.dataTables.min.css">
  <script type="text/javascript" charset="utf8" src="//cdn.datatables.net/1.10.16/js/jquery.dataTables.min.js"></script>
</head>


  <body class="theme-base-0d layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to ML4Code</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Machine Learning for Big Code and Naturalness
        </a>
      </h1>
      <p class="lead">Research on machine learning for source code.</p>      
    </div>

  <nav class="sidebar-nav">
   <div class="sidebar-item"><p style="font-size: 12px">Search related work <input type='text' id='searchTarget' size="16"/> <button onClick="search();">Go</button></p></div>
   <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
   <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
   <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
   <a class="sidebar-nav-item" href="/topic-viz.html">Topic-based Explorer</a>

   <a class="sidebar-nav-item" href="/base-taxonomy/">Core Taxonomy</a>


  <a class="sidebar-nav-item" href="/resources.html">Resources, Courses &#38; Events</a>
  <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
  </nav>

  <div class="sidebar-item">
    <p style="font-size: 12px">Contact <a href="https://miltos.allamanis.com">Miltos Allamanis</a> about this survey or website.
    <span style="font-size: 9px">
      Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
    </span></p>
  </div>
</div></div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Question Independent Grading using Machine Learning: The Case of Computer Program Grading</h1>
  <h5>G. Singh, S. Srikant, V. Aggarwal. KDD 2016</h5>
  <p>
    
      [<a href="https://dl.acm.org/citation.cfm?id=2939696" target="_blank">PDF</a>]
    
      [<a href="http://research.aspiringminds.com/" target="_blank">website</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Question Independent Grading using Machine Learning: The Case of Computer Program Grading' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Question Independent Grading using Machine Learning: The Case of Computer Program Grading' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    &nbsp;<a href='http://academic.microsoft.com/#/search?iq=Question%20Independent%20Grading%20using%20Machine%20Learning:%20The%20Case%20of%20Computer%20Program%20Grading' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/ms-academic.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#education">education</a></tag>
    
  </p>
      
      
      <p><p>Learning supervised models to grade open-ended responses is an expensive process. A model has to be trained for every prompt/question separately, which in turn requires graded samples. In automatic programming evaluation specifically, the focus of this work, this issue is amplified. The models have to be trained not only for every question but also for every language the question is offered in. Moreover, the availability and time taken by experts to create a labeled set of programs for each question is a major bottleneck in scaling such a system. We address this issue by presenting a method to grade computer programs which requires no manually assigned labeled samples for grading responses to a new, unseen question. We extend our previous work (by Srikant, Aggarwal; KDD 2014) wherein we introduced a grammar of features to learn question specific models. In this work, we propose a method to transform those features into a set of features that maintain their structural relation with the labels across questions. Using these features we learn one supervised model, across questions for a given language, which can then be applied to an ungraded response to an unseen question. We show that our method rivals the performance of both, question specific models and the consensus among human experts while substantially outperforming extant ways of evaluating codes. We demonstrate the system single s value by deploying it to grade programs in a high stakes assessment. The learning from this work is transferable to other grading tasks such as math question grading and also provides a new variation to the supervised learning approach.</p>
</p>
</div>

    </div>

  </body>
</html>
